# PySpark e Apache HOP - processamento e pipelines de dados

---

Curso sobre o Apache HOP, uma das principais ferramentas de ajuste, tratamento, preparação e geração de arquivos de dados, com construção de pipelines e workflows e sobre PySpark, com a criação de cluster para processamento distribuido utilizando scripts em Python tendo a execução desses realizadas dentro do Apache Spark, que distribui o processamento em nós interligados dentro de um ambiente de cluster.

Disponível em: [Udemy](https://www.udemy.com/course/pyspark-e-apache-hop-processamento-e-pipelines-de-dados/learn/lecture/30028604#overview)

---
